{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowを始めよう　メモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowの実行環境を整え、基本知識についておさらいしましょう。\n",
    "Kerasのサイト https://keras.io/ja/\n",
    "\n",
    "TensorFlowはKerasを土台にして開発されたライブラリです。すなわち、TensorFlowを知るとはKerasを知ることに繋がり、Kerasを知る事はニューラルネットワークを知る事に繋がります。もちろんニューラルネットワークを理解するためには数学を知っている必要があるのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "１　ソースコードの解読\n",
    "\n",
    "まず、TensorFlow.org のチュートリアルから以下のソースコードを眺めてみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このソースコードを読み解くにあたり、１行１行詳しく調べて全体を理解しようと試みます。\n",
    "１ー１　データの入力・変換\n",
    "＜２行目の解釈＞\n",
    "mnist = tf.keras.datasets.mnist\n",
    "コードの２行目からmnistという知らない英単語が出てきました。概要を理解するため以下のページを参照してみます。\n",
    "https://en.wikipedia.org/w/index.php?title=MNIST_database\n",
    "\n",
    "ざっくりまとめると、ディープラーニングをするためのデータだそうです。\n",
    "MNIST データベース　ー＞　ディープラーニング　ー＞　結果出力\n",
    "上記の流れになると思います。\n",
    "本来、ディープラーニングをするためのデータは統計的手法を用いて回収する必要があります。しかし、今回のケースではMNISTデータベースが元からあるそうです。\n",
    "\n",
    "\n",
    "＜４行目の解釈＞\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "さて、４行目からタプル形式でMNISTデータを読み込みます。\n",
    "＜５行目の解釈＞\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "ここで、なぜデータを255.0で割っているのか気になります。そこで、調べてみることにしました。適当にインターネットを検索してすぐにたどり着いた結果が以下のURLです。\n",
    "http://may46onez.hatenablog.com/entry/2016/07/14/122047\n",
    "\n",
    "そうです。CG技術者にとっては当たり前の知識ですが画素数が２５５の場合は255.0で割るのです（画素は０〜２５５で表されます）。なぜか？Kerasは０から１の範囲の要素を持つベクトルデータを処理するからだ。\n",
    "\n",
    "まとめ：２行目から４行目まではデータの入力と変換です。おそらく、ここからモデルを導入し、レイヤーを多重化して深層学習（ディープラーニング）を実現していきます。本腰を入れます。\n",
    "\n",
    "１−２　モデルの構築\n",
    "＜７行目の解釈＞\n",
    "model = tf.keras.models.Sequential\n",
    "モデルを定義し、レイヤーを代入していきます。Sequentialは連続の意味で、一般的に最もよく使われる深層学習のモデルであるとTensorFlow.orgは述べています。\n",
    "＜８行目の解釈＞\n",
    "  tf.keras.layers.Flatten(),\n",
    "さて、このFlatten( )関数は何をしているのか？興味津々でインターネットで調べてみると直ちに以下のサイトにたどり着いた。\n",
    "\n",
    "http://aidiary.hatenablog.com/entry/20161120/1479640534\n",
    "\n",
    "なるほど、画像データは四次元のテンソルデータであり、一次元のデータに変換する必要があるのだ。このFlatten( )関数の作用がわかった。\n",
    "＜９行目の解釈＞\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "いよいよ、深層学習の真髄を見出せそうだ。まず、Denseとは何か？\n",
    "しばらく考えてインターネットで探した結果、以下のURLを見つけた。\n",
    "https://teratail.com/questions/105940\n",
    "なるほど密度か！と思った瞬間に５１２の意味も理解する。画素は２５６種類（０〜２５５）であるため、あるノードにインプットするエッジは２５６、アウトプットするエッジも２５６であるから合計５１２ではないか！（まだ怪しい解釈だ）\n",
    "ちなみにactivation=tf.nn.relu のreluは活性化関数です。\n",
    "https://ja.wikipedia.org/wiki/活性化関数\n",
    "＜１０行目の解釈＞\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "Dropout関数は一体何をしているのでしょうか？適当にインターネットから以下のURLを見つけました。\n",
    "http://arakan-pgm-ai.hatenablog.com/entry/2017/09/09/003000\n",
    "過学習を抑制するためにあるそうです？\n",
    "＜１１行目の解釈＞\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "どうやらソフトマックス回帰を実施しているそうです。\n",
    "https://blog.amedama.jp/entry/2016/02/08/204551\n",
    "\n",
    "７行目から１１行目で深層学習のためのモデルの構造が作られています。そのモデル（抽象的なもの）を具現化するために次のステップが必要になります。\n",
    "１−３　モデルのコンパイル\n",
    "＜１３行目の解釈＞\n",
    "model.compile(optimizer='adam',\n",
    "１３行目からのコンパイル(compile)メソッドでモデルをコンパイルします。\n",
    "http://bluewidz.blogspot.com/2017/09/keras.html\n",
    "上記のURLからオプティマイザーの種類がわかります。\n",
    "ざっくりオプティマイザーをまとめると、ディープラーニングのトレーニングの種類のことです。\n",
    "＜１４行目の解釈＞\n",
    "              loss=‘sparse_categorical_crossentropy',\n",
    "Loss Functionは日本語で目的関数と呼ばれます。\n",
    "https://en.wikipedia.org/wiki/Loss_function\n",
    "この関数は仮設関数を導くための関数と以下のURLは説明しています。\n",
    "http://tech.mof-mof.co.jp/blog/machine-learning-cost-function.html\n",
    "＜１５行目の解釈＞\n",
    "              metrics=['accuracy'])\n",
    "よくわからないので以下のURLを見つけました。\n",
    "https://qiita.com/mytk0u0/items/d11ce0c7393e96149fa6\n",
    "簡単に言うと正答率を評価するそうです。しかし、特殊な方法で正答率を導きます。\n",
    "\n",
    "以上の１３行目から１５行目は終わりです。\n",
    "今までの流れは、（１）データの入力　（２）モデルの構成　（３）モデルのコンパイル　です。最後にディープラーニングを実行します。\n",
    "\n",
    "１−４　ディープラーニングの実行\n",
    "\n",
    "＜１７行目の解釈＞\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "この関数は以下のURLによると、機械学習の回数を指定するそうです。\n",
    "https://keras.io/ja/models/sequential/\n",
    "＜１８行目の解釈＞\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "https://keras.io/ja/models/sequential/\n",
    "上記のURLをもう一度参照すると、損失数を出力するそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "２　実行結果\n",
    "いよいよ、実行してみます。出力結果は以下の通りです。\n",
    "\n",
    "SFV-Server:git_test hikaru$ python kerastest.py\n",
    "dyld: warning, LC_RPATH $ORIGIN/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow in /Library/Python/2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so being ignored in restricted program because it is a relative path\n",
    "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
    "11493376/11490434 [==============================] - 13s 1us/step\n",
    "11501568/11490434 [==============================] - 13s 1us/step\n",
    "Epoch 1/5\n",
    "2018-08-16 15:04:29.225522: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "60000/60000 [==============================] - 21s 346us/step - loss: 0.2221 - acc: 0.9334\n",
    "Epoch 2/5\n",
    "60000/60000 [==============================] - 18s 294us/step - loss: 0.0975 - acc: 0.9698\n",
    "Epoch 3/5\n",
    "60000/60000 [==============================] - 17s 284us/step - loss: 0.0709 - acc: 0.9779\n",
    "Epoch 4/5\n",
    "60000/60000 [==============================] - 17s 282us/step - loss: 0.0539 - acc: 0.9829\n",
    "Epoch 5/5\n",
    "60000/60000 [==============================] - 17s 291us/step - loss: 0.0433 - acc: 0.9866\n",
    "10000/10000 [==============================] - 1s 95us/step\n",
    "\n",
    "３　ディスカッション\n",
    "　ディープラーニングの実行のために、（１）開発環境の構築　（２）ディープラーニングの知識　（３）プログラミングの技術　（４）データ収集　などが必要である。\n",
    "さらに深く理解するために数学の知識を深め、Kerasのサイトで実行方法の文法を暗記していく必要があるだろう。TensorFlowの本でも買おうかと考える。\n",
    "\n",
    "これからの学習の流れとして、\n",
    "（１）Kerasの学習\n",
    "（２）TensorFlowの学習\n",
    "（３）自己流で現実世界に適用\n",
    "とします。\n",
    "（（１）と（２）は同時並行でいい気がする）\n",
    "\n",
    "今回の学習で何を知らないのか、何を学習するべきかがわかった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
